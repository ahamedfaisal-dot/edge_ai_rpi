# Edge AI Pothole Detection â€” Live Pi Camera Pipeline (`rpicam-vid`)

## Overview

This folder contains **`run_with_pi_cam.py`** â€” the live-camera variant of the
Edge AI Road Anomaly Detection system.

Instead of reading a pre-recorded video file, the detector streams frames directly
from a **Raspberry Pi Camera Module v2** using the built-in **`rpicam-vid`** tool
that ships with Raspberry Pi OS. No external Python camera library is needed â€”
`rpicam-vid` is launched as a subprocess and raw **YUV420 (I420)** frames are piped
directly into the Python process via `stdout`.

The detection logic extends the parent project's ONNX pipeline with:

```
rpicam-vid (subprocess)
   â†’ YUV420 stdout pipe
   â†’ YUV â†’ BGR conversion
   â†’ Frame Downscaling
   â†’ Preprocessing (resize / normalise)
   â†’ YOLOv5 ONNX Inference
   â†’ Post-Processing (conf + area + aspect filters)
   â†’ NMS
   â†’ Temporal Voting
   â†’ Visualisation + Logging (log / CSV / SQLite / JSON / JPEG)
```

---

## Hardware Requirements

| Component | Details                                      |
| --------- | -------------------------------------------- |
| SBC       | Raspberry Pi 4 Model B (4 GB RAM+)           |
| OS        | Raspberry Pi OS 64-bit (Bookworm / Bullseye) |
| Camera    | Pi Camera Module **v2** (IMX219)             |
| Interface | CSI-2 ribbon cable (included with camera)    |
| Storage   | 16 GB+ microSD (Class 10 / A1)               |
| Power     | Official 5 V / 3 A USB-C PSU                 |

> **Important:** `rpicam-vid` is a system-level tool bundled with Raspberry Pi OS.
> It talks to the camera hardware directly via **libcamera** â€” no Python camera
> library (`picamera2`, `picamera`) is required or used.

---

## Software Dependencies

```bash
# Python packages only
pip install opencv-python numpy onnxruntime
```

`rpicam-vid` is already installed on Raspberry Pi OS â€” no additional install needed.

```bash
# Verify rpicam-vid is available
rpicam-vid --version
```

> The script will exit immediately with a clear error if `rpicam-vid` fails to start.

---

## File Structure

```
with_pi_cam/
â”œâ”€â”€ run_with_pi_cam.py   â† Main live-camera detection script
â””â”€â”€ README.md            â† This document

# Parent project (model + shared modules):
../Code_in_PI4/
â”œâ”€â”€ best.onnx            â† YOLOv5 pothole detector (ONNX, 320Ã—320)
â”œâ”€â”€ runvid.py            â† Original video-file pipeline
â”œâ”€â”€ temporal_voting.py   â† MultiFrameVoter (imported by this script)
â”œâ”€â”€ mahalanobis_detector.py
â””â”€â”€ fallback_anomaly.py

# Auto-created at runtime:
../logs/
â”œâ”€â”€ pothole_<SESSION>.log         â† Text log (per session)
â”œâ”€â”€ detections_<SESSION>.csv      â† CSV of all confirmed detections
â”œâ”€â”€ summary_<SESSION>.json        â† JSON session summary
â”œâ”€â”€ potholes.db                   â† SQLite database (all sessions)
â””â”€â”€ detection_images/
    â””â”€â”€ <SESSION>_frame<N>.jpg    â† JPEG snapshots of confirmed frames
```

---

## How to Run

```bash
# Navigate to the folder
cd edge_ai_rpi/with_pi_cam

# Run the Pi Camera pipeline
python run_with_pi_cam.py
```

### Controls

| Key      | Action                                           |
| -------- | ------------------------------------------------ |
| `q`      | Quit (closes window, writes logs, prints stats)  |
| `Ctrl+C` | Safe stop (same cleanup as `q`)                  |

---

## Architecture â€” Full Detailed Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   rpicam-vid SUBPROCESS                          â”‚
â”‚  Command:                                                        â”‚
â”‚    rpicam-vid --width 640 --height 480                           â”‚
â”‚               --framerate 5 --codec yuv420                       â”‚
â”‚               --nopreview --timeout 0 --output -                 â”‚
â”‚                                                                  â”‚
â”‚  â€¢ Launched via subprocess.Popen                                 â”‚
â”‚  â€¢ Raw YUV420 (I420) data written to stdout pipe                 â”‚
â”‚  â€¢ Uses libcamera driver â€” works with Pi Camera v2               â”‚
â”‚  â€¢ 2-second warm-up after launch before reading starts           â”‚
â”‚  â€¢ Exits if rpicam-vid process terminates unexpectedly           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚  stdout pipe (YUV420 bytes)
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FRAME READING (read_frame)                     â”‚
â”‚  â€¢ FRAME_BYTES = 640 Ã— 480 Ã— 3 // 2  (YUV420 I420 layout)       â”‚
â”‚  â€¢ Uses readinto loop into a fixed bytearray buffer              â”‚
â”‚  â€¢ Guarantees exactly one full frame per call                    â”‚
â”‚  â€¢ Returns None if pipe closes (triggers clean shutdown)         â”‚
â”‚  â€¢ Converts: YUV420 â†’ BGR via cv2.COLOR_YUV2BGR_I420            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚  BGR frame (480 Ã— 640 Ã— 3)
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FRAME DOWNSCALING                           â”‚
â”‚  â€¢ Scale factor: FRAME_SCALE = 0.45                              â”‚
â”‚    640 â†’ ~288 px wide,  480 â†’ ~216 px tall                       â”‚
â”‚  â€¢ Interpolation: INTER_NEAREST (fastest on RPi CPU)             â”‚
â”‚  â€¢ Reduces pixel count ~80% before inference                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PREPROCESSING (preprocess)                   â”‚
â”‚  1. Resize to 320Ã—320  (INFER_SIZE Ã— INFER_SIZE)                 â”‚
â”‚     using INTER_NEAREST                                          â”‚
â”‚  2. BGR â†’ RGB  (flip channel axis [::-1])                        â”‚
â”‚  3. HWC â†’ CHW  (transpose to PyTorch tensor layout)              â”‚
â”‚  4. uint8 â†’ float32,  divide by 255  â†’ [0.0, 1.0]               â”‚
â”‚  5. Add batch dim: shape becomes (1, 3, 320, 320)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   YOLOv5 ONNX INFERENCE                          â”‚
â”‚  â€¢ Model file  : best.onnx  (YOLOv5, exported to ONNX)          â”‚
â”‚  â€¢ Provider    : CPUExecutionProvider                            â”‚
â”‚  â€¢ intra_op_num_threads = 4  (all 4 RPi4 cores)                  â”‚
â”‚  â€¢ inter_op_num_threads = 1                                      â”‚
â”‚  â€¢ Execution mode : ORT_SEQUENTIAL                               â”‚
â”‚  â€¢ Graph opt level: ORT_ENABLE_ALL                               â”‚
â”‚  â€¢ Output shape: (1, N, â‰¥5)                                      â”‚
â”‚    Each row = [x_centre, y_centre, width, height, conf, cls...]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              POST-PROCESSING + FILTERS (postprocess)             â”‚
â”‚                                                                  â”‚
â”‚  Filter 1 â€” Confidence:                                          â”‚
â”‚    Discard if conf < CONF_THRES (0.40)                           â”‚
â”‚    (raised from 0.20 to eliminate weak false positives)          â”‚
â”‚                                                                  â”‚
â”‚  Filter 2 â€” Scale & convert:                                     â”‚
â”‚    sx = frame_w / 320,  sy = frame_h / 320                       â”‚
â”‚    Convert centre-format â†’ corners (x1, y1, x2, y2)             â”‚
â”‚    Clamp to frame boundary                                       â”‚
â”‚                                                                  â”‚
â”‚  Filter 3 â€” Size:                                                â”‚
â”‚    Discard if box width or height < 10 px or > 1000 px           â”‚
â”‚                                                                  â”‚
â”‚  Filter 4 â€” Area ratio (new):                                    â”‚
â”‚    Discard if box area > 30% of total frame area                 â”‚
â”‚    (prevents huge false boxes covering entire scene)             â”‚
â”‚                                                                  â”‚
â”‚  Filter 5 â€” Aspect ratio (new):                                  â”‚
â”‚    aspect = box_width / box_height                               â”‚
â”‚    Discard if aspect < 0.3  (too tall/thin)                      â”‚
â”‚    Discard if aspect > 3.0  (too wide/flat)                      â”‚
â”‚    (potholes are roughly equant or slightly wide)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  NON-MAXIMUM SUPPRESSION (nms)                   â”‚
â”‚  â€¢ Sort boxes by confidence (descending)                         â”‚
â”‚  â€¢ Greedy pick: always keep the highest-confidence box           â”‚
â”‚  â€¢ Remove overlapping boxes where IoU > IOU_THRES (0.4)         â”‚
â”‚  â€¢ Repeat until box list is empty                                â”‚
â”‚                                                                  â”‚
â”‚    IoU = Intersection Area / Union Area                          â”‚
â”‚                                                                  â”‚
â”‚  Purpose: deduplicate multiple detections on same pothole        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TEMPORAL VOTING (MultiFrameVoter)                   â”‚
â”‚  Imported from: temporal_voting.py (parent project)              â”‚
â”‚                                                                  â”‚
â”‚  â€¢ Maintains a sliding window of the last 3 frames               â”‚
â”‚  â€¢ Detection confirmed only if â‰¥ 2 of 3 frames detect something  â”‚
â”‚  â€¢ Window size = 3,  vote threshold = 2  (configurable)          â”‚
â”‚  â€¢ Rejects single-frame camera glitches / lighting artifacts     â”‚
â”‚  â€¢ No "sticky latch" â€” clean binary output each frame            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                          â”‚
                â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    VISUALISATION (draw)  â”‚  â”‚    DETECTION LOGGING (log_detection)â”‚
â”‚                          â”‚  â”‚                                    â”‚
â”‚ â€¢ Green boxes on frame   â”‚  â”‚ Triggered only when BOTH:           â”‚
â”‚   for every detection    â”‚  â”‚   confirmed=True AND detections>0  â”‚
â”‚ â€¢ "POTHOLE X.XX" label   â”‚  â”‚                                    â”‚
â”‚   above each box         â”‚  â”‚ Outputs:                           â”‚
â”‚ â€¢ Red "POTHOLE DETECTED!"â”‚  â”‚  .log  â€” Python logging (INFO)     â”‚
â”‚   banner at top-left     â”‚  â”‚  .csv  â€” row per confirmed event   â”‚
â”‚ â€¢ HUD (bottom of frame): â”‚  â”‚  .db   â€” SQLite WAL, buffered 10x  â”‚
â”‚   â€“ FPS (cyan)           â”‚  â”‚  .jpg  â€” JPEG snapshot of frame    â”‚
â”‚   â€“ Frame # (yellow)     â”‚  â”‚          (85% quality)             â”‚
â”‚   â€“ Total dets (magenta) â”‚  â”‚                                    â”‚
â”‚   â€“ Proc time ms (orange)â”‚  â”‚ Columns logged:                    â”‚
â”‚ â€¢ Resized to 640Ã—360     â”‚  â”‚  timestamp, frame_id, num_boxes,   â”‚
â”‚   for stable display     â”‚  â”‚  max_conf, boxes_json, fps,        â”‚
â”‚ â€¢ Window: "Pothole       â”‚  â”‚  process_ms                        â”‚
â”‚   Detection"             â”‚  â”‚                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       FPS THROTTLE                               â”‚
â”‚  â€¢ TARGET_FRAME_TIME = 1.0 / 5 = 200 ms                         â”‚
â”‚  â€¢ Sleep remainder after each loop iteration                     â”‚
â”‚  â€¢ cv2.waitKey handles both sleep and key press check            â”‚
â”‚  â€¢ Console log every 2 seconds: frame/fps/proc/detections        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                 [q pressed / Ctrl+C / pipe closed]
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLEAN SHUTDOWN (finally)                      â”‚
â”‚  1. cam_proc.terminate() + cam_proc.wait()  â€” kill rpicam-vid   â”‚
â”‚  2. cv2.destroyAllWindows()                                      â”‚
â”‚  3. Flush SQLite buffer, close CSV file                          â”‚
â”‚  4. Write summary_<SESSION>.json                                 â”‚
â”‚  5. Print final statistics to console                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Configuration Parameters

| Parameter            | Value  | Description                                     |
| -------------------- | ------ | ----------------------------------------------- |
| `TARGET_FPS`         | 5      | Frames per second cap (RPi CPU optimised)        |
| `FRAME_SCALE`        | 0.45   | Pre-inference downscale ratio                   |
| `CONF_THRES`         | **0.40** | Min confidence â€” raised from 0.20 to cut FPs  |
| `IOU_THRES`          | 0.4    | NMS IoU overlap threshold                       |
| `INFER_SIZE`         | 320    | ONNX model input size (px)                      |
| `CAM_WIDTH`          | 640    | Camera capture width (px)                       |
| `CAM_HEIGHT`         | 480    | Camera capture height (px)                      |
| `MAX_BOX_AREA_RATIO` | 0.30   | Reject boxes covering > 30% of frame *(new)*    |
| `MIN_ASPECT`         | 0.3    | Reject boxes narrower than this ratio *(new)*   |
| `MAX_ASPECT`         | 3.0    | Reject boxes wider than this ratio *(new)*      |
| `window_size`        | 3      | Temporal voter sliding window length            |
| `vote_threshold`     | 2      | Minimum votes to confirm a detection            |
| `intra_op_num_threads` | 4    | ONNX CPU threads (matches RPi4 cores)           |
| `_DB_FLUSH_EVERY`    | 10     | SQLite write-buffer size (rows before commit)   |

---

## rpicam-vid vs picamera2

| Aspect        | **rpicam-vid** (this script)        | `picamera2` (Python lib)         |
| ------------- | ----------------------------------- | -------------------------------- |
| Type          | System CLI tool (subprocess)        | Python library                   |
| Install       | Pre-installed on Raspberry Pi OS    | `pip install picamera2`          |
| Frame format  | YUV420 (I420) via stdout pipe       | BGR888 via Python API            |
| Latency       | Very low (direct kernel pipe)       | Low (DMA-backed)                 |
| Python import | Not needed (subprocess.Popen)       | `from picamera2 import Picamera2`|
| Availability  | Raspberry Pi OS only                | Raspberry Pi OS only             |

> This script uses **`rpicam-vid`** because it is built into Raspberry Pi OS 64-bit
> and requires no additional Python packages.

---

## YOLOv5 ONNX Model Details

| Property            | Value                                        |
| ------------------- | -------------------------------------------- |
| Architecture        | **YOLOv5**                                   |
| Model file          | `best.onnx`                                  |
| Input tensor        | `(1, 3, 320, 320)` float32 RGB               |
| Output tensor       | `(1, N, â‰¥5)` â€” (x_c, y_c, w, h, conf, â€¦)   |
| Detector class      | Pothole / road anomaly                       |
| Export format       | ONNX opset 12+                               |
| Inference runtime   | ONNX Runtime CPU                             |
| Approximate RPi FPS | 5â€“7 FPS (with FRAME_SCALE=0.45)              |

---

## Component Responsibilities

| Section                  | Responsibility                                                     |
| ------------------------ | ------------------------------------------------------------------ |
| **rpicam-vid launch**    | Spawn subprocess, pipe YUV420 stdout, verify it started           |
| **`read_frame()`**       | Blocking readinto loop â†’ YUV2BGR â†’ return BGR frame               |
| **ONNX session setup**   | Load best.onnx, 4-thread CPU, full graph optimisation             |
| **`preprocess()`**       | Resize â†’ RGB flip â†’ CHW transpose â†’ normalise â†’ batch dim         |
| **`postprocess()`**      | Conf + size + area-ratio + aspect-ratio filters, box scaling      |
| **`nms()`**              | Greedy IoU-based duplicate suppression                            |
| **`MultiFrameVoter`**    | 3-frame sliding-window majority vote (from `temporal_voting.py`)  |
| **`log_detection()`**    | Write to CSV, buffer SQLite rows, save JPEG snapshot              |
| **`log_session_end()`**  | Flush DB, close CSV, write JSON summary                           |
| **Main loop**            | Capture â†’ downscale â†’ infer â†’ filter â†’ vote â†’ draw â†’ HUD â†’ pace  |
| **`finally` block**      | Kill rpicam-vid, close windows, flush all logs, print stats       |

---

## Differences vs `runvid.py` (Video File Pipeline)

| Feature              | `runvid.py`                | `run_with_pi_cam.py`              |
| -------------------- | -------------------------- | --------------------------------- |
| Input source         | Pre-recorded `.mp4`        | Live Pi Camera via `rpicam-vid`   |
| Capture API          | `cv2.VideoCapture(path)`   | `subprocess.Popen` + pipe read    |
| Frame format         | Video codec (BGR)          | Raw YUV420 â†’ BGR conversion       |
| Loop restart         | Rewinds video on EOF       | Continuous live stream            |
| MultiFrameVoter      | Imported                   | Imported (same module)            |
| Conf threshold       | 0.20                       | **0.40** (stricter)               |
| Extra box filters    | None                       | Area ratio + aspect ratio checks  |
| Logging              | Console only               | `.log` / `.csv` / `.db` / `.json` / `.jpg` |
| Camera fallback      | None                       | None (exits if rpicam-vid fails)  |

---

## Logging â€” Output Files

Every run creates a unique `SESSION_ID = YYYYMMDD_HHMMSS` and writes:

| File | Format | Contents |
|------|--------|----------|
| `pothole_<SESSION>.log` | Text | All INFO logs â€” session start/end + each detection event |
| `detections_<SESSION>.csv` | CSV | One row per confirmed detection: timestamp, frame, boxes, FPS, ms |
| `potholes.db` | SQLite (WAL) | `sessions` + `detections` tables, accumulates across all runs |
| `summary_<SESSION>.json` | JSON | Session totals: frames, detections, duration, avg FPS |
| `detection_images/<SESSION>_frame<N>.jpg` | JPEG 85% | Frame snapshot at the moment of each confirmed detection |

---

## Performance Optimisations

| Technique              | Detail                                                         |
| ---------------------- | -------------------------------------------------------------- |
| Frame downscale 0.45   | Reduces pixels ~80% before inference                          |
| INTER_NEAREST          | Fastest OpenCV resize interpolation                            |
| Input size 320         | ~4Ã— fewer FLOPs vs default YOLOv5 640                         |
| 4 CPU threads          | Saturates all RPi4 cores via `intra_op_num_threads`           |
| Sequential exec mode   | Avoids thread-switching overhead                               |
| Full graph opt         | ONNX Runtime fuses and optimises compute graph                 |
| FPS cap (5)            | Prevents CPU spinning; paced via cv2.waitKey                   |
| Pipe buffer Ã— 4        | Prevents rpicam-vid pipe stalls                                |
| SQLite WAL + buffer    | Batches DB writes every 10 rows â€” avoids per-frame I/O        |
| Rolling 10-frame avg   | FPS/proc-time stats without unbounded memory                   |

---

## Output â€” Console

```
âœ… Model: best.onnx (320x320)
âœ… Inference size : 320x320
âœ… Target FPS     : 5
âœ… Conf threshold : 0.4  â† raised to reduce false positives
ğŸ¥ Starting rpicam-vid â€¦
âœ… rpicam-vid started | 640x480 @ 5fps

ğŸš€ Running | FPS=5 | scale=0.45 | conf>=0.4
Press Ctrl+C or 'q' to quit

Frame   110 | FPS: 5 | Proc: 138ms | Total detections: 2
Frame   120: 1 pothole(s) confirmed
Frame   160 | FPS: 5 | Proc: 135ms | Total detections: 3
...
âœ… Stopped by user

ğŸ“Š Final Statistics:
   Total frames    : 320
   Total time      : 64.0s
   Average FPS     : 5.0
   Total detections: 6
   Avg processing  : 137ms
   Model           : best.onnx (320x320)
   Logs saved to   : ../logs
âœ… Done!
```

---

## Output â€” Display Window

Window title: **"Pothole Detection"**

- **Green rectangle** around each detection (drawn every frame with detections)
- **"POTHOLE X.XX"** confidence label above each box
- **Red "POTHOLE DETECTED!"** banner at top-left when confirmed
- **HUD** at bottom of frame:
  - FPS (cyan)  Â·  Frame # (yellow)  Â·  Total detections (magenta)  Â·  Proc time ms (orange)
- Resized to **640Ã—360** for stable output size

---

## Troubleshooting

| Problem                       | Likely Cause               | Fix                                                    |
| ----------------------------- | -------------------------- | ------------------------------------------------------ |
| `rpicam-vid failed` on start  | Camera not connected/enabled | Check CSI ribbon, enable camera in `raspi-config`    |
| `Error loading model`         | `best.onnx` not found      | Ensure `best.onnx` is in the same folder as the script |
| Black / green screen          | YUV format mismatch        | Confirm `--codec yuv420` is supported by your RPi OS   |
| Very low FPS (< 2)            | CPU overloaded / no cooling | Add heatsink/fan; lower `CAM_WIDTH`/`CAM_HEIGHT`     |
| `rpicam-vid: command not found` | Old Raspberry Pi OS version | `sudo apt update && sudo apt upgrade`               |
| `temporal_voting` not found   | Script run from wrong dir  | Make sure `temporal_voting.py` is on the Python path   |
| No display window             | Headless SSH session       | Use X11 forwarding (`ssh -X`) or run with VNC          |

---

## Quick Start (Raspberry Pi)

```bash
# 1. Enable camera (if not already)
sudo raspi-config
# â†’ Interface Options â†’ Camera â†’ Enable

# 2. Verify rpicam-vid works
rpicam-vid --width 640 --height 480 --timeout 3000 --nopreview

# 3. Install Python dependencies
pip install opencv-python numpy onnxruntime

# 4. Navigate to folder (best.onnx must be here or update MODEL_PATH)
cd edge_ai_rpi/with_pi_cam

# 5. Run
python run_with_pi_cam.py
```

---

## Authors

Ahamed Faisal A
Sanji Krishna M P
Subiksha A

**Target Hardware:** Raspberry Pi 4
**Camera:** Raspberry Pi Camera Module v2 (IMX219, CSI)
**Camera Tool:** `rpicam-vid` (built-in to Raspberry Pi OS)
**Project Status:** Active Development
